\documentclass[14pt]{extreport}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}

\usepackage{array}
\usepackage{setspace}
\usepackage[pdftex]{graphicx}
\usepackage{graphicx}
\graphicspath{{img/}}
\usepackage{subcaption}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}


\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage[nottoc,numbib]{tocbibind} %bibliography in table of contents

\DeclareMathOperator*{\argmaxA}{arg\,max}


\usepackage{titlesec} % decrease chapter heading sizes
    \titleformat{\chapter}[display]
      {\normalfont\large\bfseries\filcenter}{\chaptertitlename\ \thechapter}{0pt}{\Large} %huge 10 Huge
    \titlespacing*{\chapter}
      {0pt}{0pt}{10pt} %10 30 20 default

\makeatletter
\renewcommand{\@biblabel}[1]{#1.} % Заменяем библиографию с квадратных скобок на точку:
\renewcommand{\baselinestretch}{1.5}


\makeatother

\usepackage[left=3.0cm,right=1.5cm,top=2.0cm,bottom=2.0cm,bindingoffset=0cm]{geometry}

\begin{document}

   \begin{titlepage}{
        \thispagestyle{empty}\newgeometry{left=2.5cm,right=1.5cm,top=0cm,bottom=0.2cm,bindingoffset=0cm}\setstretch{1}
        \begin{center}
            {\footnotesize
                Министерство образования и науки Российской Федерации\\
                Федеральное государственное автономное образовательное учреждение\\
                высшего профессионального образования\\
            }

            <<Уральский федеральный университет\\
             имени первого Президента России Б.Н.Ельцина>>

             \vskip+0.5cm

            Институт математики и компьютерный наук\\
            Кафедра вычислительной математики

            \vskip+25mm

            {\bf \LARGE
                Поиск вредоносной активности в DNS трафике \\
            }

            \vskip+15mm
        \end{center}
	
        \vfill
        \noindent\begin{parbox}[t]{9cm}{\small
                \vspace{2.0cm}
                Допустить к защите:

                \bigskip
                \bigskip
                \bigskip

                \hbox to45mm{\hrulefill}

                \bigskip

                <<\,\hbox to10mm{\hrulefill}\,>>  \hbox to25mm{\hrulefill}  2016 г.
            }
            \end{parbox}
            \begin{parbox}[t]{9cm}{\small  \setstretch{1}
                Выпускная квалификационная работа \\
                на степень бакалавра по направлению\\
                02.03.02
                Фундаментальная информатика \\
                и информационные технологии	 \\
                студента группы МК-420002 \\
                                \bigskip
                Меньших Ивана Александровича\\
                Научный руководитель\\
                доцент Солодушкин Святослав Игоревич\\
            }
            \end{parbox}
        \vfill
        \centerline{Екатеринбург}
        \centerline{2016}
        }\restoregeometry
    \end{titlepage}
\newpage
    \tableofcontents

\newpage
    \chapter{Введение в проблему поиска вредоносной активности}

Важнейшей задачей, стоящей перед системными администраторами, является защита корпоративной сети и пресечение любых вредоносных взаимодействий клиентов сети и сети интернет. Схожая задача стоит перед сервисами, предоставляющими услуги DNS фильтрации. Анализ логов DNS сервера позволяет выделить в общей массе запросов <<подозрительные>> (то есть те, которые соответствуют коммуникации зараженного хоста и, например, управляющего C\&C сервера). 

В реальности, анализ DNS логов проводить крайне трудно, потому что каждый клиент генерирует большое количество запросов. Даже при заходе на сайт пользователь генерирует множество запросов. Как правило, при загрузке страницы происходят обращения на сторонние сервера для загрузки стилей, скриптов, изображений и так далее. Даже когда пользователь ничего не делает, его ПК генерирует запросы. Это могут быть обновления программного обеспечения, синхронизация часов и так далее. Особенно это заметно в новых версиях Windows: операционная система старается <<радовать>> пользователя своей интерактивностью и постоянно запрашивает новости, курсы валют, отправляет различную информацию о его действиях на свои сервера для <<персонализации>> взаимодействия.

В этой работе будут рассмотрены различные способы анализа DNS трафика, на базе которых можно выделить домены, которые, вероятно, используются для коммуникации между зараженным хостом и ботмастером.

\newpage
Общая идея заключается в анализе паттернов взаимодействия зараженных клиентов и C\&C серверов. Кроме того, речь будет идти о фильтрации запросов. Это очень важный аспект, ведь известно, что <<Garbage In, Garbage Out>>. Будут сделаны несколько предположений о структуре паттернов взаимодействия, а также предложены методы анализа.

\chapter{Формальная постановка задачи}
	Для того, чтобы приступить к решению этой проблемы, необходимо формализовать задачу.
	
	{\bfДано:}
		
		1. DNS логи ($querylog$). Определим их как множество $Q$. Каждая запись в нём представима в виде вектора признаков $\vec{query}$$\in$$Q$, который \textbf{обязательно} содержит $source\_ip$ (ip адрес клиента, который совершает запрос) и $domain$ (домен, который пользователь желает <<разрешить>>). Кроме того, в нём могут содержаться дополнительные данные (например время, когда был совершен запрос, подробно структура $\vec{query}$ будет описана далее).
		
		2. Белый список доменов ($whitelist$). Будем использовать <<самые частопосещаемые>> домены, для этого воспользуемся списками от Alexa и Quantcast)
		
		3. Черный список доменов ($blacklist$). Будем использовать базы компании SkyDNS и прочие источники.
	
	{\bfНеобходимо:} 
	
	1. Выбрать из $querylog$ подмножество 
	запросов $\{\vec{query_1}, \vec{query_2}, \vec{query_3}, \dots\}$, которые были совершены к вредоносным доменам и выделить имена этих доменов. На самом деле, нас больше интересуют сами доменные имена, так как по ним легко осуществлять блокировку	(что и является основной нашей задачей)
	
	2. Выделить общие паттерны взаимодействия клиентов и вредоносных доменов, описать внешний вид графа запросов.
	
	\section{Структура $\vec{query}$}
	\label{sec:strq}
		\begin{tabular}{| l | r |}
			\hline
			Поле & Описание \\ \hline
			$domain$ & Домен, который был запрошен пользователем \\ \hline 
			$source\_ip$ &  IP адрес пользователя \\ \hline
			$rcode$ &  Код возврата DNS сервера \\ \hline
			$qtype$ &  Код запрашиваемого типа записи \\ \hline
			$timestamp$ &  Временная метка получения сервером запроса \\ \hline

		\end{tabular}
		
	
	\section{Структура $whitelist$ и $blacklist$}
	\begin{tabular}{| l | r |}
			\hline
			Поле & Описание \\ \hline
			$domain$ & Доменное имя \\ \hline 
			$cats$ & Cписок категорий, к которым принадлежит домен \\ \hline

	\end{tabular}
	\section{Словарь}
	\begin{tabular}{p{3cm} p{10cm}}
	\hline
			Домен & Символьное имя, служащее для идентификации областей — единиц административной автономии в сети Интернет — в составе вышестоящей по иерархии такой области. \\ 
			TLD & Домен верхнего (первого) уровня (например .com, .eu) \\
			iLD & Домен i уровня \\
			Хост & Клиентский ПК \\
			Ботнет & Сеть из заражённых хостов, управляемая ботмастером через C\&C сервер \\
			C\&C & Управляющий сервер ботнета \\
			whois & Сервис, позволяющий узнать информацию о регистрации доменного имени, а также о его владельце \\
			pDNS & Техника, позволяющая отслеживать изменения в изменении соответствия доменных имён ip адресам \\
			 \hline

	\end{tabular}
	
	\chapter{Ботнеты}
	\section{Описание}
	Ботнет - сеть инфицированных хостов, управляемая извне. Бот, по своей сути, это вредоносное программное обеспечение, которое позволяет злоумышленнику удаленно управлять устройством пользователя.
	
	Заражение подобным программным обеспечением может происходить через
уязвимости в используемом ПО (например через браузер и эксплуатации 0-day
exploit, который позволяет исполнить произвольный код за пределами
«песочницы» браузера). Кроме того, заражение может произойти с помощью
«социальная инженерии», где вредоносное ПО маскируется под полезное
содержимое, например вложение в электронном письме.

	Проблема детектирования ботнетов стоит очень остро, так как они растут вместе с интернетом. Например один из самых больших - ботнет Ponmocup, по данным компании FoxIT, достигал размера 15000000 хостов.
	
	Очень важно научиться выявлять ботнеты, а именно, в рамках текущей
работы, нас интересуют доменные имена, которые используют C\&C сервера.
Это поможет нам предупредить пользователей, чьи ПК проявляют
«аномальную» активность, схожую с активностью члена ботнета.
	
	\newpage
	\section{Топология}
	Можно выделить две основных топологии построения ботнетов $\cite{communication}$
	

	\begin{figure}[H]
	
	\begin{subfigure}{0.5\textwidth}
	\includegraphics[width=0.9\linewidth, height=5cm]{star_topology.png}
	\caption{<<Звезда>>}
	\label{fig:subim1}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
	\includegraphics[width=0.9\linewidth, height=5cm]{tree_topology.png}
	\caption{<<Дерево>>}
	\label{fig:subim2}
	\end{subfigure}
	 
	\caption{Популярные варианты топологии ботнета}
	\label{fig:image2}
	\end{figure}
	Топология, изображённая на Рис. 3.1.(a) является, пожалуй, самой часто встречающейся и простой. Зараженные хосты напрямую коммуницируют с C\&C сервером. Основная её уязвимость - централизация. Благодаря этому аспекту, отследить управляющий сервер гораздо проще. Соответственно, и обезвредить такой ботнет легче. Из плюсов стоит отметить быструю коммуникацию, т.к. отсутствует <<прослойка>> между клиентом и сервером.
	Как расширение данной топологии, можно рассматривать вариант, в котором используется несколько серверов. Это убирает проблему с единой точкой отказа, а также позволяет балансировать нагрузку по географической принадлежности (для общения с хостом используется сервер, который к нему физически ближе). Минус - дополнительные затраты на сервера, а также сложность в синхронизации между серверами.
	
	Топология из Рис. 3.1.(b) встречается реже, но является более устойчивой. Смысл заключается в том, что зараженные хосты общаются с управляющим сервером через <<прокси>>, в качестве которого выступают другие зараженные хосты. Это позволяет скрыть реальный C\&C сервер, что препятствует его обнаружению. Кроме того, ботнет проще будет <<продать>> по частям, продавая контроль над некоторым поддеревом данного графа (а дерево может быть достаточно глубоким).
	
	Также встречается топология вида P2P, где хосты соединены между собой и образуют небольшие плотные графы. Это самый устойчивый вариант, но им сложно управлять. В нём просто нет места для C\&C сервера и команды, фактически, передаются какому-либо хосту, который распространяет эту команду всем остальным.

	
	\newpage
	\section{Стратегии уклонения}
	Для того, чтобы предотвратить обнаружение управляющий серверов и уничтожение ботнета, ботмастеры используют различные стратегии, препятствующие этому $\cite{communication}$.
	\subsection{IP Flux (fast flux)}
	Один из вариантов - использовать много ip адресов для одного доменного имени и маленький TTL для A записи в DNS пакете. Данный приём можно усложнить, меняя также ip адреса соответствующий NS серверов.
	
	Изначально, данный приём позволял легитимными сайтами балансировать нагрузку между серверами еще на этапе разрешения доменного имени. Этот способ до сих пор используется разными сайтами (например google.com)
	
	\subsection{Domain Flux}
	Другой вариант - использовать много доменных имён, разрешающихся в один ip адрес. Именно этот подход чаще всего используется в настоящее время. Связано это с исчерпанием IPv4 диапазона. В это же время, доменное имя практически ничего не стоит. Кроме того, владея 2LD доменом, можно легко генерировать множество 3LD доменов (example.com -> *.example.com) .
	Как правило, для этого используются специальные алгоритмы, которые генерируют домены на основе системного времени. Класс таких доменов называется DGA. Они являются короткоживущими (несколько часов - несколько недель) и используются для одноразовой коммуникации. 
	
   \section{Коммуникация}
   \begin{figure}[H]
   	\centering
	\includegraphics[scale=0.8]{communicate.png}
	\caption{Принцип работы}
	\end{figure}
	Процесс коммуникации можно разделить на несколько шагов, они изображены на Рис. 3.2. Опишем подробней эту схему:
	
	1. Заражённый хост и управляющий сервер синхронизируют время путём отправки запроса по протоколу NTP к некоторому серверу точного времени. Эта стадия происходит не всегда, если не требуется синхронизации по минутам/секундам. Зачастую, хватает точности до суток.
	
	2. Хост и C\&C сервер генерируют доменные имена, основываясь на текущей временной метке.
	
	3. C\&C сервер регистрирует эти доменные имена
	
	4. Клиент опрашивает сгенерированные доменные имена по списку и пытается получить ip адрес
	
	5. Клиент устанавливает соединение с C\&C сервером и получает необходимые команды/обновления
	
Таким образом, теперь мы имеем базовое представление о ботнетах, их структуре и поведении.

	\chapter{Групповая активность}
	\label{chap:groupact}
	\section{Описание}
	Один из подходов поиска ботнетов - отслеживание групповой активности клиент-домен. Основываясь на работе $\cite{groupact}$ сделаем несколько предположений:
	
	1. Заражённых хостов в сети фиксированное количество
	
	2. Взаимодействие заражённых хостов и C\&C сервера проявляется переодически
	
	3. Как правило, используется техника domain flux, которая была описана выше (используется много доменных имён и мало ip адресов)
	
	Исходя из данных предположений, можно составить алгоритм, который выделит подозрительные коммуникации между группами хостов и доменом.
	
	\section{Алгоритм}
	
	Алгоритм поиска групповой активности можно разделить на 3 стадии: сбор информации о запросах пользователей, фильтрация запросов и детектирование подозрительной активности. 
	
	Изначально, мы делим все $querylog$ на <<окна>>, в текущем случае использовалось окно длины 1 час. Выбрано это число из таких соображений: частая коммуникация не свойственна ботнетам, поэтому не имеет смысл использовать окно меньшего размера. Кроме того, при слишком маленьком окне, высок шанс ложного срабатывания алгоритма, а при слишком большом - слабой чувствительности.
	
	Первая функция группирует все пары запросов ($client\_ip$, $domain$) по домену. Подобная агрегация позволяет получить представление о том, кто именно запрашивает конкретный домен.
	\begin{algorithmic}
	\Function{SearchInfo}{$querylog$ [by hour]}
	\State $data\gets Dictionary<str, set>$
	\For{($client\_ip$, $domain$) in $querylog$} 
	
		\State $data[domain]$.add($client$)
	\EndFor
	
	\State \Return $data$
	\EndFunction
	\end{algorithmic}

	Следующая функция фильтрует полученные данные. Нам необходимо исключить все доменные имена, которые есть в $whitelist$, а также те доменные имена, которые запрашиваются малым количеством пользователей (хорошим вариантом будет значение $threshould$ $\in$ 3, 4, 5, 6, 7)
	

	\begin{algorithmic}
	\Function{FilterQueries}{$data<str,set>$, $whitelist$, $threshould$}
	\For{$domain$ in $data$}
		\If{$domain$ in $whitelist$ OR length(data[domain]) < threshould}
			\State $ip\_list\gets data[domain]$
			\State $data$.remove($domain$)
			\State $data$.pop\_values($ip\_list$)
		\EndIf
		
		
	\EndFor
	\State \Return $data$
	\EndFunction
	\end{algorithmic}
	
	Последняя функция выполняет предварительную обработку $querylogs$, выбирает доменные имена, к которым в разные временные промежутки обращаются, в основном, одни и те же пользователи, что, в рамках наших начальных предположений, говорит о вредоносности такого домена
	\begin{algorithmic}
	\Function{DetectBotnetDomain}{$querylogs<list>$, $sim\_score$}
	\State $data\_arr\gets List<dictionary>$
	\State $botnet\_domains\gets Set<str>$
	\For{$querylog$ in $querylogs$}
		\State $curr\_data\gets SearchInfo(querylog)$
		\State $curr\_data\gets FilterQueries(curr\_data)$
		\State $data\_arr$.append($curr\_data$)

	\EndFor
	\For{$data_1$ in $data\_arr$}
		\For{$data_2$ in $data\_arr$}
			\If{$data_1$ $\ne$ $data_2$}
				\For{$domain$ in $data_1$ $\cap$ $data_2$}
					\State $curr\_sim\gets Similarity(data_1[domain], data_2[domain])$
					\If{$curr\_sim$ > $sim\_score$}
						\State $botnet\_domains$.add($domain$)
					\EndIf
				\EndFor
			\EndIf
		\EndFor
	\EndFor
	\State \Return $botnet\_domains$
	\EndFunction
	\end{algorithmic}
	
	
	Немного о функции $similarity$, она выражает <<схожесть>> между клиентами, которые запрашивают один и тот же домен. В работе [2] предлагается для этих целей использовать такую функцию: 
	\begin{equation}
	\label{eq:ga-orig}
	similarity(ipList_1, ipList_2) = \frac{1}{2} * (\frac{C}{A} + \frac{C}{B}) (A\ne0, B\ne0)
	\end{equation} 
	где $A = |ipList_1|$, $B = |ipList_2|$, $C = |ipList_1\cap ipList_2|$
	
	Эксперименты показали, что есть более подходящая функция - расстояние Джаккара: 
	\begin{equation}
	\label{eq:ga-jacc}
	similarity(iplist_1, iplist_2) = \frac{|ipList_1\cap ipList_2|}{|ipList_1\cup ipList_2|}
	\end{equation} 
	
	Таким образом, мы рассмотрели вариант детектирования подозрительных доменных имен, основанный на групповой активности пользователей.
	
	\chapter{Графовая модель запросов}
	\label{chap:graph}
	\section{Описание}
	В прошлой главе мы рассматривали активность групп пользователей, относительно доменных имён. В этой же главе, мы <<усовершенствуем>> эту идею и перейдём к графовой модели запросов пользователей.
	
	Рассмотрим двудольный неориентированный граф ($H\times D$, $E$), где $H$ - множество хостов, $D$ - множество доменных имён, ($h_i$, $d_j$)$\in$ $E$, если пользователь $h_i$ запрашивал домен $d_j$. 
	На основе этой модели предлагается вычислять для каждого домена некоторую оценку, которая будет говорить о его вредоносности или же наоборот, о том, что домен <<чист>>. Как мы увидим далее, такая оценка вычисляется и для хостов, но её в работе мы использовать не будем.

	Идея заключается в том, чтобы передавать через <<соседей>> в графе оценку от доменов к клиентам и обратно. Этот процесс является итерационным.
	
			
	Вспомним, что у нас есть $blacklist$ и $whitelist$, в текущем разделе мы будем пользоваться ими для инициализации оценок
	\section{Первый вариант ранжирования доменов}
	В работе [3] предлагается для оценки использовать процесс случайного блуждания по графу. Использование <<блуждания>> обусловлено тем, что граф получается слишком большой, поэтому они, фактически, вместо точной оценки вычисляют её приближение. В этой работе, мы будем рассматривать граф, который генерируется на основе 3 часов логов. Так как он помещается в RAM, то мы не будем организовывать случайное блуждание. Мы будем <<честно>> на каждой итерации проходить от каждой вершины ко всем её соседям и пересчитывать оценку.

	Обозначим правила пересчёта. На каждой итерации, они симметрично вычисляют оценку для каждой вершины из доли (вначале для хостов, потом для доменов)
	\begin{equation}
	\label{eq:dr1-black}
	black\_score(h_i) = \sum_{d_j: (h_i, d_j)\in E} \frac{black\_score(d_j)}{deg(d_j)}
	\end{equation}
	\begin{equation}
	\label{eq:dr1-white}
	white\_score(h_i) = \sum_{d_j: (h_i, d_j)\in E} \frac{white\_score(d_j)}{deg(d_j)}
	\end{equation}
	
	Возникает закономерный вопрос, а зачем нам так много различных оценок, нельзя ли ограничиться просто $black\_score$ ? Как оказываться, его недостаточно, потому что любой популярный <<чистый>> домен может получить высокую оценку по этому параметру просто из за своей популярности (в графе к нему будет идти много ребёр, как от заражённых, так и от <<чистых>> хостов). Именно для этого вводится $white\_score$, который у популярных доменов будет также высоким.
	
	Теперь нам нужно <<взвесить>> две полученных оценки, что мы будем делать за счёт $union\_score$. Это просто отношение <<негативных>> оценок ко всем остальным.
	\begin{equation}
	\label{eq:dr1-union}
	union\_score(d_i) = \frac{black\_score(d_i)}{black\_score(d_i) + white\_score(d_i)}
	\end{equation}
	
	\subsection{Алгоритм}
	Опишем алгоритм пересчёта всех оценок на двудольном графе
	\begin{algorithmic}
	\Function{CalcScores}{$graph<H\times D, E>$, $max\_iter$, $whitelist$,  $blacklist$, $init\_weight$}
	\State $black\_score = Dictionary<str, float>$
	\State $white\_score = Dictionary<str, float>$
	\State $union\_score = Dictionary<str, float>$
	
	
	\For{$domain$ in $blacklist$}
		\State $black\_score[domain] = -init\_weight$
	\EndFor
	
	\For{$domain$ in $whitelist$}
		\State $white\_score[domain] = init\_weight$
	\EndFor
	\While{$max\_iter > 0$}
		\For{$h_i\in H$}
			\State $black\_score(h_i) = \sum_{d_j: (h_i, d_j)\in E} \frac{black\_score(d_j)}{deg(d_j)}$
			\State $white\_score(h_i) = \sum_{d_j: (h_i, d_j)\in E} \frac{white\_score(d_j)}{deg(d_j)}$
		\EndFor
		
		\For{$d_j\in D$}
			\State $black\_score(d_j) = \sum_{h_i: (h_i, d_j)\in E} \frac{black\_score(h_i)}{deg(h_i)}$
			\State $white\_score(d_j) = \sum_{h_i: (h_i, d_j)\in E} \frac{white\_score(h_i)}{deg(h_i)}$
		\EndFor
		\State $max\_iter\gets max\_iter-1$
	\EndWhile
	\For{$d_i\in D$}
		\State $union\_score(d_i) = \frac{|black\_score(d_i)|}{|black\_score(d_i)| + |white\_score(d_i)|}$
	\EndFor
	\State \Return $union\_score$
	\EndFunction
	\end{algorithmic}
	
	\section{Второй вариант ранжирования доменов}
	Теперь мы используем ту же графовую модель, но поговорим уже о другом правиле пересчёта. Это правило упоминается в работе $\cite{rank}$. Само правило выглядт так:
	\begin{equation}
	\label{eq:dr2-rank}
	rank\_score(d_j) = \sum_{h_i: (h_i, d_j)\in E} \frac{rank\_score(h_i)}{deg'(h_i)}
	\end{equation}
	
	Эта формула практически идентична $black\_score$ из прошлой главы, но тут предлагается использоваться в качестве $deg'(h_i)$ не степень вершины в текущем графе, а некоторую заранее посчитанную статистику (например построить много таких графов и посчитать среднюю степень каждой такой вершины, это число использовать для $deg'$). Этот алгоритм очень напоминает алгоритм $PageRank$, но на самом деле, между ними много отличий
	\\\\
	\begin{tabular}{|p{8cm}|p{8cm}|}
			\hline
			$rank\_score$ & $PageRank$ \\ \hline
			Редкое посещение домена <<здоровыми>> клиентами увеличивает шанс того, что домен вредоносный & Больше связей с хорошими страницами увеличивает шанс того, что страница получит высокий ранг \\ \hline 
			Два типа вершин &  Один тип вершин \\ \hline
			Неориентированный граф &  Ориентированный граф \\ \hline
			Фактически, мы имеет разбиение на 3 класса: вредоносные домены, чистые домены и неизвестные домены &  Нет разбиения, только ранжирование \\ \hline
			Вычисляем риск &  Вычисляем популярность \\ \hline
			Очень сильно зависит от начальной инициализации весов & Не зависит от начальных весов \\ \hline
	\end{tabular}
	\\ \\
	Это правило пересчёта также похоже на алгоритм $HITS$, если мы превратим наш граф в ориентированный (все рёбра от хостов к доменам) и будем использовать $auth(d_i)$
	
	\subsection{Алгоритм}
		\begin{algorithmic}
	\Function{CalcRank}{$graph<H\times D, E>$, $max\_iter$, $whitelist$,  $blacklist$, $init\_weight$, $deg'$}
	\State $rank\_score = Dictionary<str, float>$
	
	\For{$domain$ in $blacklist$}
		\State $rank\_score[domain] = -init\_weight$
	\EndFor
	
	\For{$domain$ in $whitelist$}
		\State $rank\_score[domain] = init\_weight$
	\EndFor

	\While{$max\_iter > 0$}
		\For{$h_i\in H$}
			\State $rank\_score(h_i) = \sum_{d_j: (h_i, d_j)\in E} \frac{rank\_score(d_j)}{deg'(d_j)}$
		\EndFor
		
		\For{$d_j\in D$}
			\State $rank\_score(d_j) = \sum_{h_i: (h_i, d_j)\in E} \frac{rank\_score(h_i)}{deg'(h_i)}$
		\EndFor
		\State $max\_iter\gets max\_iter-1$
	\EndWhile
	\State \Return $rank\_score$
	\EndFunction
	\end{algorithmic}

	\section{Структура сообществ в графе}
	\label{ssec:communitystruct}
	Усложним нашу первоначальную модель графа. У нас вновь будет двудольный неориентированный граф ($H\times D$, $E$), где $H$ - множество хостов, $D$ - множество доменных имён. Вся разница в правиле построения рёбер. Ребро ($h_i$, $d_j$, $w_k$) $\in$ $E$, если пользователь $h_i$ запрашивал домен $d_j$ и этот запрос завершился ошибкой (значение поля $rcode$ из DNS-пакета > 0 $\cite{dnsrfc}$, оно присутствует в $querylog$), вес $w_k$ вычисляется как количество запросов, завершившихся ошибкой, от $h_i$ к $d_j$. Впервые такой граф фигурировал в работе $\cite{commstruct}$.
	\\
	\begin{figure}[H]
	\center
	\includegraphics[width=0.9\linewidth]{fail-graph.png}
	\caption{Граф неудачных DNS-запросов (синие - хосты, красные - домены)}
	
	\label{fig:subim1}
	\end{figure}
	
	
	Из него можно выделить типичные паттерны подграфов
	\begin{enumerate}
	\item <<Звезда>> с доменом в центре. Причины появления:
	\begin{enumerate}
	\item Домен, который существовал ранее, но больше не существует
	\item Домен, который является кандидатом на C\&C ботнета
	\item Типичная ошибка настройки клиента (например префикс DNS)
	\item Другое
	\end{enumerate}
	\item <<Звезда>> с хостом в центре. Причины появления:
	\begin{enumerate}
	\item Ошибка настройки клиента
	\item Перебор возможных доменных имён C\&C сервера
	\item Другое
	\end{enumerate}
	
	\item Ребро из одного хоста к одному домену. Соответствует запросу редкого домена.
	
	\item Плотный двудольный подграф, соответствует <<сильной>> связи между группами пользователей и группой доменов. Может быть порождён группой клиентов - членов одного и того же ботнета.
	
	\item <<Дерево>>, которое представимо в виде объединения компонент, перечисленных выше
	\end{enumerate}
	
	\subsection{Алгоритм}
	Общая идея состоит в построении таких графов и выделении из них плотных подграфов, для которых строится множество признаков, по которому строится классификатор. Опишем основные процедуры этого процесса
	
	В первую очередь, нам нужно построить граф ($H \times D$, $E$), при этом выбросим <<мусор>>. Для этого, при построении графа, мы удалим вершины, соответствующие доменам из $whitelist$ (предполагаю, что он содержит популярные домены, на подобие googe.com), также, мы удалим те рёбра, которые имеют $rcode \in (format\_error, serv\_failt, ...)$, т.е. ошибками на стороне DNS сервера, или же при формировании пакета $\cite{dnsrfc}$.
	\\
	\begin{algorithmic}
	\Function{ConstructGraph}{$querylog$, $whitelist$}
	\State $graph \gets ((\emptyset \times \emptyset$), $\emptyset$)

	\For{$query$ in $querylog$}
		\If{$query[rcode] == 0 \vee query[domain] \in whitelist$}
			\State CONTINUE
		\EndIf
		\If{$query[rcode] \in  (format\_error, serv\_failt, ...)$}
			\State CONTINUE
		\EndIf
		\State $graph.add\_node(query[client\_ip])$
		\State $graph.add\_node(query[dname])$
		\State $graph.add\_edge((query[client\_ip], query[dname]))$
		
	\EndFor
	\State \Return $graph$
	\EndFunction
	\end{algorithmic}
	
	
	Следующий шаг - декомпозиция полученного графа. Процесс будет проходить в два этапа: на первом этапе делается $BFS$, и для полученных компонент связности проводится процесс ко-кластеризации. Достаточно <<плотные>> компоненты мы будем рассматривать на следующем шаге.
	\begin{algorithmic}
	\Function{DecomposeGraph}{$graph$, $min\_density$}
	\State $dense\_subgraphs\gets Array()$
	\State $connected\_subgraphs\gets BFS(graph)$
	\For{$graph$ in $connected\_subgraphs$}
		\State $partition \gets coclustering(graph)$
		\For{$g$ in $partition$}
			\If{$density(g)$ > $min\_density$}
				\State $dense\_subgraphs.append(g)$
			\EndIf
		\EndFor
	\EndFor
	\State \Return $dense\_subgraphs$
	\EndFunction
	\end{algorithmic}
	
	Определим функцию, которая будет говорить о <<плотности>> подграфа таким образом
	$$density = \frac{|E|}{|H|*|D|}$$
	
	Что касается функции $coclustering$, существуют несколько способов сделать это. В статье $\cite{nmtf}$ предлагается решать задачу 3-факторизации матрицы исходного графа. Опишем формальную постановку задачи 3-факторизации.
	
	Пусть $A \in \mathbb{R}_{+}^{m \times n}$ - матрица сопряженности двудольного графа,  $m = |H|, n = |D|$, мы хотим её разложить на произведение трёх матриц $$ U \in \mathbb{R}_{+}^{m \times k}, S \in \mathbb{R}_{+}^{k \times l}, V \in  \mathbb{R}_{+}^{n \times l}$$
	$$ A \approx USV^T$$
	Оптимизационная задача выглядит так
	$$\min_{U \ge 0, S \ge 0, V \ge 0}{|| A - USV^T||^2}$$
	При условиях, что  $U$ и $V$  - ортогональные, $||.||$ - норма Фробениуса
	
	Смысл этого разложения заключается в том, что матрицы $U$ и $V$ отвечают за кластеры по строкам и по столбцам , а матрица $S$ описывает <<тесноту связи>> между парами кластеров (то есть между группой хостов и группой доменов). Описание решения данной задачи можно найти в $\cite{nmtf}$.
	
	В результате, мы получаем множество двудольных плотных подграфов, из каждого извлекаем список признаков
	
	\begin{enumerate}
		\item Медиана по всем TTL доменов в подграфе. Этот признак может выделить группы короткоживущих доменов, что может свидетельствовать о fast-flux доменах, которые часто используют ботмастера
		\item Отношение количества доменов в графе на количество хостов
		\item Лексические признаки.
		\begin{enumerate}
			\item Расстояние между распределение 1-грамм и 2-грамм до равномерного распределения. Для этого есть симметричное расстояние Кульбаха-Лейбнера. Довольно часто доменные имена генерируются с помощью ГСЧ, который, по умолчанию, выдаёт равномерное распределение.
			\item Редакторское расстояние между всеми доменами в подграфе. Опять таки, для доменов сгенерированных с помощью ГСЧ будет большим.
			\item Кол-во пересекающихся 3-грамм с 3-граммами из $whitelist$ и $blacklist$. Также, к $whitelist$ можно добавить словари популярных языков.
		\end{enumerate}
	\end{enumerate}  

	Это достаточно небольшая группа признаков, но уже она даёт результат в распознавании вредоносных подграфов. Больше признаков можно получить, используя $whois$ и $pDNS$.
	
	На последнем шаге, мы обучаем классификатор на полученных признаках (для этого, естественно, нужно собрать обучающую выборку, в этом нам сильно помогут $whitelist$ и $blacklist$). Видно, что этот подход сильно отличается от упоминаемых ранее, так как он базируется не на доменных именах, а на целых подграфах $(H' \times D', E')$. Зато именно этот метод позволяет посмотреть на DNS трафик с более <<высокого>> уровня абстракции и выделить паттерны взаимодействия группы хостов - группы доменов.
	
	В результате, мы получаем алгоритм, который на вход принимает граф, а на выходе получаем множество плотных подграфов, для каждого из которых мы может ответить на вопрос, является ли эта активность вредоносной.
	
	\chapter{Объединение подходов по оценке доменных имён}
	В данной работе были рассмотрены несколько подходов детектирования вредоносной активности. В разделе ~\ref{ssec:communitystruct} мы получили готовый результат, но он применим только к группам пользователей и доменов. Теперь, нам нужно объединить остальные подходы, которые занимаются оценкой доменов, перечисленные в главах~\ref{chap:groupact} и~\ref{chap:graph}.
	
	\section{Описание признаков}
	\label{sec:desc-features}
	Хорошим вариантом является использовать техники машинного обучения, опираясь на выходные данные алгоритмов как на признаки доменов. Опишем те признаки, которые будем использовать. В качестве набора входных данных мы рассматриваем $querylog$ за 3 часа
	\begin{enumerate}
		\item [1--3.] $similarity$ (оригинальный)~\eqref{eq:ga-orig}  (по всем двойкам часов)
		\item [4--6.]$similarity$ (джаккард)~\eqref{eq:ga-jacc} (по всем двойкам часов)
		\item [7--9.] Мощность пересечения множеств клиентов по домену~\eqref{chap:groupact} (по всем двойкам часов)
		\item [10.] $black\_score$ (по 3 часам) ~\eqref{eq:dr1-black}
		\item [11.] $white\_score$ (по 3 часам) ~\eqref{eq:dr1-white}
		\item [12.] $union\_score$ (по 3 часам) ~\eqref{eq:dr1-union}
		\item [12.] $rank\_score$ (по 3 часам) ~\eqref{eq:dr2-rank}
		
	\end{enumerate}
	\section{Постановка задачи классификации}
	Этот набор признаков будем использовать в дальнейшем. Далее ставится задача
	
	{\bf
    Дано:
	}

	\begin{tabular}{p{6cm} p{7.5cm}}
		 $\mathcal{X}=(X_1,\ldots,X_k)$ & входные вектора признаков признаков, $X_i\in\mathbb{R}^n$\\[0.1cm]
		 $\mathcal{Y}=(y_1,\ldots,y_k)$ & вектор правильных ответов (вредоносный ли домен), $y_i\in{0,1}$\\[0.1cm]
		 $(\mathcal{X},\mathcal{Y})$ & обучающая выборка  \\[0.1cm]
		 $(\mathcal{X'},\mathcal{Y'})$ & тестовая выборка  \\[0.1cm]
		 $ROC\_AUC$ & Функция площади под ROC-кривой \\[0.1cm]
		 $CLF$ & Множество классификаторов\\[0.1cm]
		 $PARAM$ & Множество параметров для классификатора\\[0.1cm]

	 \end{tabular}
	 
	 {\bf
    Найти:
	 } \\

	Классификатор $clf \in CLF$ такой, что $ROC\_AUC(\mathcal{X'},\mathcal{Y'}) \rightarrow \max$ 
	 \newline
	
	Стоит пояснить, что такое $ROC\_AUC$ и вспомогательные понятия, необходимые для его вычисления. 
	
	$ROC\_curve$ - характеристика качества классификатора, зависимость доли верных положительных классификаций от доли ложных положительных классификаций при изменении порога решающего правила. Для построения этой кривой необходимо вычислять $FPR$ и $TPR$ по формулам ниже
	
	$$FPR(clf, (X, Y)) = \frac{\sum_{(x, y) \in (X, Y)}[clf(x)=+1][y=-1]}{\sum_{(x, y) \in (X, Y)}[y=-1]}$$
	
	$$TPR(clf, (X, Y)) = \frac{\sum_{(x, y) \in (X, Y)}[clf(x)=+1][y=+1]}{\sum_{(x, y) \in (X, Y)}[y=+1]}$$
	
	Где $clf$ - решающее правило, $X$ - множество векторов, $Y$ множество правильных ответов
	
	$ROC\_curve$ проходит через точки (0, 0), соответствующей максимальному значению порога и (1, 1), соответствующей минимальному значению порога.
	$ROC\_AUC$ вычисляется как площадь под кривой $ROC\_curve$.
	
	В качестве множества классификаторов возьмём $RandomForest$ и $AdaBoost$, т.к. ансамблевые модели достаточно мощные и <<неприхотливые>> в плане входных данных (не требуют, например, нормализации данных).
	
	Для каждого из них будем подбирать основные параметры. В случае с $AdaBoost$ будем подбирать количество деревьев и скорость обучения. В случае же с $RandomForest$ будем выбирать количество деревьев, информационный критерий и максимальное количество признаков, по которым можно производить разделение.
	 
	 
	\section{Алгоритм обучения классификатора}
	Перечислим шаги, необходимые для получения итогового классификатора
	\begin{enumerate}
	\item Весь объем $querylog$ делим на части по 3 часа в каждой, каждая часть будет использоваться как входные данные для итогового алгоритма. Шаги далее будут описаны для работы с одной такой частью.
	
	\item Вычисляем признаки 1--9 из~\ref{sec:desc-features}. Для их вычисления не требуется никакой дополнительной информации
	
	\item Строим двудольный граф $(H \times D, E)$
	
	\item Берем исходные $blacklist$ и $whitelist$, перемешиваем и делаем 4 независимых разбиения на обучающую и тестовую выборки в соотношении 70/30 
	(такой подход именуется $KFold CV$)
	
	\item Для каждого такого разбиения $(X\_train, y\_train)$, $(X\_test, y\_test)$
	\begin{enumerate}
		\item Вычисляем признаки 10--13 (используя для начальной инициализации $(X\_train, y\_train)$
		\item Для каждой пары $(clf_i, param_i) \in CLF\times PARAM$
		\begin{enumerate}
			\item Обучанем классификатор $clf_i$ с параметрами $param_i$ на множестве $(X\_train, y\_train)$
			\item Вычисляем $ROC\_AUC(X\_test, y\_test)$
		\end{enumerate}
	
	\end{enumerate}
	
	\item Вычисляем
	\begin{equation}
	\label{eq:clf-opt}
	clf, param = \argmaxA_{(clf_i, param_i) \in CLF\times PARAM}mean(ROC\_AUC(X\_test, y\_test))
	\end{equation}
	\item Берем целиком $whitelist$ и $blacklist$ и вычисляем признаки 10--13
	\item Обучаем классификатор $clf$ с параметрами $param$ на всей выборке
	\end{enumerate}
	
	
	Итоговый классификатор мы единожды используем для поиска новых вредоносных доменов на том же графе. После чего процесс повторяется для новой трёхчасовой последовательности $querylog$.
	
	Фундаментальный принцип, заложенный в процесс обучения классификатора - это кросс-валидация. Далее, я буду понимать под классификатором двойку $(clf, param) \in (CLF, PARAM)$. 
	
	Выбирается самый <<стабильный>> классификатор относительно $k$ различных произвольных разбиений обучающей выборки (напомню, что мы разбиваем на 4 части), таким образом получается самый <<качественный>> вариант (метрика $ROC\_AUC$ удобна для сравнения классификаторов между собой). Слово <<стабильный>> следует понимать так: для любого из исходных разбиений выборки, классификатор работает достаточно <<качественно>>
	
	Принцип, заложенный в шаги 5-6 называется $GridSearch$. Обучение классификатора - это некоторая задача оптимизации. Тут же мы строим оптимизационную задачу на более высоком уровне. Мы оптимизируем по всем классификаторам, максимизируя <<качество>> классификации. Эта <<метазадача>>~\eqref{eq:clf-opt} позволяет выбрать наилучший классификатор из представленных.
	

\chapter{Техническая реализация}
В этой главе речь пойдет непосредственно о реализации алгоритмов, предложенных в данной работе и использовании их в реальной жизни. В качестве источника $querylog$ будем использовать DNS сервера компании SkyDNS. 
	
%% \addcontentsline{toc}{chapter}{Литература}
\begin{thebibliography}{99}

\bibitem{communication} Gunter Ollmann, ``Botnet Communication Topologies. Understanding the intricacies of botnet command-and-control'', 2009.

\bibitem{groupact} Hyunsang Choi, Hanwoo Lee, Heejo Lee, Hyogon Kim, ``Botnet Detection by Monitoring Group Activities in
DNS Traffic''.

\bibitem{graphscore} Keisuke Ishibashi, Tsuyoshi Toyono, Makoto Iwamura, ``Botnet Detection Combining DNS and Honeypot Data''.

\bibitem{rank} Frank Denis, ``Malware vs Big Data'', pp. 30 -- 31.
\bibitem{commstruct} Y. Jin, E. Sharafuddin, and Z. L. Zhang, “Unveiling core network-wide communication patterns through application traffic activity graph decomposition,” in Proceedings of the eleventh international joint conference on Measurement and modeling of computer systems. ACM, 2009, pp. 49 -- 60.
\bibitem{dnsrfc}  P. Mockapetris, ``DOMAIN NAMES - IMPLEMENTATION AND SPECIFICATION, RFC1035''.
\bibitem{nmtf} C. Ding, T. Li, W. Peng, H. Park, ``Orthogonal nonnegative matrix t-factorizations for clustering'', in Proceedings of the 12th ACM SIGKDD
international conference on Knowledge discovery and data mining, ser.
KDD ’06. New York, NY, USA: ACM, 2006, pp. 126–135.
\end{thebibliography}


\end{document} 