{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Классификатор вредоносных доменов </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"SR\")\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим все нужные нам трансформеры и эстиматоры (тут вообще надо будет аккуратней сделать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from tldextract import TLDExtract\n",
    "from binlog_reader import binlog_reader\n",
    "import numpy as np\n",
    "\n",
    "class GroupActivity(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def _similarity(self, ips_1, ips_2):\n",
    "        a, b = float(len(ips_1)), float(len(ips_2))\n",
    "        c = float(len(ips_1 & ips_2))\n",
    "        return 0.5 * (c/a + c/b), c / len(ips_1 | ips_2), int(c)\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, d2ip_idx_list):\n",
    "        logger.debug(\"Start calc group activity\")\n",
    "        all_domains = list(it.chain.from_iterable([d2ip.keys() for d2ip in  d2ip_idx_list]))\n",
    "        result = {domain: dict() for domain in all_domains}\n",
    "        pairs = list(filter(lambda (x, y): x < y, it.permutations(range(len(d2ip_idx_list)), 2)))\n",
    "        ptn = \"({}, {})_{}\"\n",
    "\n",
    "        for idx, domain in enumerate(all_domains):\n",
    "            for l ,r in pairs:\n",
    "                left, right =  d2ip_idx_list[l].get(domain),  d2ip_idx_list[r].get(domain)\n",
    "                sim, jacc, ln = 0., 0., 0.\n",
    "                if left and right:\n",
    "                    sim, jacc, ln = self._similarity(left, right)\n",
    "                result[domain].update({ptn.format(l, r, \"sim\"): sim,\n",
    "                                       ptn.format(l, r, \"jcd\"): jacc,\n",
    "                                       ptn.format(l, r, \"length\"): ln})\n",
    "            if (idx + 1) % 100000 == 0:\n",
    "                logger.debug(\"Processed %d domains\", idx + 1)\n",
    "                \n",
    "        return result\n",
    "        \n",
    "    \n",
    "    \n",
    "class IndexCreator(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, queries_all):\n",
    "        result = []\n",
    "        for idx, queries in enumerate(queries_all):\n",
    "            logger.debug(\"Creating index, part %d/%d\", idx + 1, len(queries_all))\n",
    "            ip2d, d2ip = dict(), dict()\n",
    "            for ip, domain in queries:\n",
    "                ip2d.setdefault(ip, set())\n",
    "                ip2d[ip].add(domain)\n",
    "                d2ip.setdefault(domain, set())\n",
    "                d2ip[domain].add(ip)\n",
    "            result.append({\"ip2d\": ip2d, \"d2ip\": d2ip})\n",
    "        return result\n",
    "\n",
    "\n",
    "class IndexMerger(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, indexes):\n",
    "        ip2d_full, d2ip_full = dict(), dict()\n",
    "\n",
    "        for curr in indexes:\n",
    "            for domain in curr['d2ip']:\n",
    "                d2ip_full.setdefault(domain, set())\n",
    "                d2ip_full[domain] |= curr['d2ip'][domain]\n",
    "\n",
    "            for ip in curr[\"ip2d\"]:\n",
    "                ip2d_full.setdefault(ip, set())\n",
    "                ip2d_full[ip] |= curr['ip2d'][ip]\n",
    "        return ip2d_full, d2ip_full\n",
    "    \n",
    "\n",
    "class PairExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._extract = TLDExtract(include_psl_private_domains=True)\n",
    "    \n",
    "    def sanitize(self, domain):\n",
    "        return self._extract(domain).registered_domain\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, queries_all):\n",
    "        result = []\n",
    "        for idx, queries in enumerate(queries_all):\n",
    "            logger.debug(\"Transforming domains, part %d/%d\", idx + 1,  len(queries_all))\n",
    "            current = [(ip, self.sanitize(domain)) for ip, domain in queries]\n",
    "            current = filter(lambda (ip, domain): domain, current)\n",
    "            result.append(set(current))\n",
    "        return result\n",
    "\n",
    "\n",
    "class BLReader(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, fields):\n",
    "        self.fields = fields\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, fnames):\n",
    "        result = []\n",
    "        for idx, fn in enumerate(fnames):\n",
    "            with open(fn, 'rb') as infile:\n",
    "                logger.debug(\"Read file %s, part %d/%d\", fn, idx + 1, len(fnames))\n",
    "                reader = binlog_reader(infile, self.fields)\n",
    "                current = [tuple([query[fld] for fld in self.fields]) for query in reader]\n",
    "                result.append(set(current))\n",
    "        return result\n",
    "\n",
    "\n",
    "class PosNegDomainReader(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._extract = TLDExtract(include_psl_private_domains=True)\n",
    "\n",
    "    def sanitize(self, domain):\n",
    "        return self._extract(domain).registered_domain\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, fnames):\n",
    "        if len(fnames) != 2:\n",
    "            raise RuntimeError(\"Must be 2 files: positive and negative\")\n",
    "        result = []\n",
    "        for fn in fnames:\n",
    "            with open(fn, 'rb') as infile:\n",
    "                logger.debug(\"Read file %s\", fn)\n",
    "                current = [self.sanitize(line.strip()) for line in infile]\n",
    "                current = filter(lambda domain: domain, current)\n",
    "                result.append(set(current))\n",
    "        return result\n",
    "\n",
    "\n",
    "class FormXy(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, all_domains):\n",
    "        self.all_domains = set(all_domains)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, lst):\n",
    "        if len(lst) != 2:\n",
    "            raise RuntimeError(\"Must be list with 2 sets: positive and negative\")\n",
    "        pos, neg = lst\n",
    "        pos, neg = set(pos), set(neg)\n",
    "        inter = pos & neg\n",
    "        logger.debug(\"Positive size %d, Negative size %d, Intersection %d\", len(pos), len(neg), len(inter))\n",
    "        pos, neg = (pos - inter) & self.all_domains, (neg - inter) & self.all_domains\n",
    "        logger.debug(\"Positive after %d, Negative after %d\", len(pos), len(neg))\n",
    "        X = list(pos) + list(neg)\n",
    "        y = [1 for _ in range(len(pos))] + [-1 for _ in range(len(neg))]\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, indexes_all):\n",
    "        return [idx[self.key] for idx in indexes_all]\n",
    "    \n",
    "\n",
    "class SecureRank(ClassifierMixin):\n",
    "    def __init__(self, ip2d, d2ip, max_iter=20, init_abs_score=10.):\n",
    "        self.ip2d = ip2d\n",
    "        self.d2ip = d2ip\n",
    "        self.max_iter = max_iter\n",
    "        self.default_score = init_abs_score\n",
    "        self.f_ord = ['sc_score', 'black_score', 'white_score']\n",
    "    \n",
    "    def fit(self, domain, d_class):\n",
    "        logger.debug(\"Initialize scores\")\n",
    "        self.rank_ip = {ip: {'sc_score': 0., 'black_score': 0., 'white_score': 0.} for ip in self.ip2d}\n",
    "        self.rank_d = {d:  {'sc_score': 0., 'black_score': 0., 'white_score': 0.} for d in self.d2ip}\n",
    "        \n",
    "        for dom, cls in zip(domain, d_class):\n",
    "            if cls == 1:\n",
    "                self.rank_d[dom]['sc_score'] = -float(self.default_score)\n",
    "                self.rank_d[dom]['black_score'] = -float(self.default_score)\n",
    "                \n",
    "            elif cls == -1:\n",
    "                self.rank_d[dom]['sc_score'] = float(self.default_score)\n",
    "                self.rank_d[dom]['white_score'] = float(self.default_score)\n",
    "\n",
    "        \n",
    "        for it in range(self.max_iter):\n",
    "            logger.debug(\"Iteration %d\", it + 1)\n",
    "            \n",
    "            for ip in self.rank_ip:\n",
    "                self.rank_ip[ip]['sc_score'] = sum(self.rank_d[d]['sc_score']/len(self.d2ip[d]) \n",
    "                                                   for d in self.ip2d[ip])\n",
    "                self.rank_ip[ip]['black_score'] = sum(self.rank_d[d]['black_score']/len(self.d2ip[d]) \n",
    "                                                      for d in self.ip2d[ip])\n",
    "                self.rank_ip[ip]['white_score'] =  sum(self.rank_d[d]['white_score']/len(self.d2ip[d]) \n",
    "                                                       for d in self.ip2d[ip])\n",
    "\n",
    "            for domain in self.rank_d:\n",
    "                self.rank_d[domain]['sc_score'] = sum(self.rank_ip[ip]['sc_score']/len(self.ip2d[ip]) \n",
    "                                                      for ip in self.d2ip[domain])\n",
    "                self.rank_d[domain]['black_score'] = sum(self.rank_ip[ip]['black_score']/len(self.ip2d[ip]) \n",
    "                                                         for ip in self.d2ip[domain])\n",
    "                self.rank_d[domain]['white_score'] = sum(self.rank_ip[ip]['white_score']/len(self.ip2d[ip]) \n",
    "                                                         for ip in self.d2ip[domain])\n",
    "                \n",
    "        return self\n",
    "                \n",
    "    def transform(self, domains):\n",
    "        return [[self.rank_d[dom][f] for f in self.f_ord] for dom in domains]\n",
    "\n",
    "\n",
    "class IndentityOp(BaseEstimator, TransformerMixin, ClassifierMixin):\n",
    "    def __init__(self, info):\n",
    "        self.info = info\n",
    "        self.f_ord = self.info[self.info.keys()[0]].keys()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [[self.info[x][f] for f in self.f_ord] for x in X]\n",
    "    \n",
    "def perf_measure(y_pred, y_test):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for idx, (real, pred) in enumerate(zip(y_test, y_pred)):\n",
    "        if real == pred:\n",
    "            if real == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        else:\n",
    "            if real == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "\n",
    "    return(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычитываем файлы, обрабатываем, считаем групповую активность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-04-13 18:35:17,140 - DEBUG - Read file /home/ivan/dns-13-aprl/querylog.bin.33-1460530801, part 1/6\n",
      "2016-04-13 18:35:45,597 - DEBUG - Read file /home/ivan/dns-13-aprl/querylog.bin.33-1460534401, part 2/6\n",
      "2016-04-13 18:36:19,287 - DEBUG - Read file /home/ivan/dns-13-aprl/querylog.bin.33-1460538001, part 3/6\n",
      "2016-04-13 18:36:56,527 - DEBUG - Read file /home/ivan/dns-13-aprl/querylog.bin.33-1460541601, part 4/6\n",
      "2016-04-13 18:37:33,821 - DEBUG - Read file /home/ivan/dns-13-aprl/querylog.bin.33-1460545201, part 5/6\n",
      "2016-04-13 18:38:16,428 - DEBUG - Read file /home/ivan/dns-13-aprl/querylog.bin.33-1460548801, part 6/6\n",
      "2016-04-13 18:39:02,536 - DEBUG - Transforming domains, part 1/6\n",
      "2016-04-13 18:39:24,944 - DEBUG - Transforming domains, part 2/6\n",
      "2016-04-13 18:39:49,730 - DEBUG - Transforming domains, part 3/6\n",
      "2016-04-13 18:40:17,259 - DEBUG - Transforming domains, part 4/6\n",
      "2016-04-13 18:40:47,249 - DEBUG - Transforming domains, part 5/6\n",
      "2016-04-13 18:41:17,491 - DEBUG - Transforming domains, part 6/6\n",
      "2016-04-13 18:41:54,057 - DEBUG - Creating index, part 1/6\n",
      "2016-04-13 18:41:57,959 - DEBUG - Creating index, part 2/6\n",
      "2016-04-13 18:42:02,600 - DEBUG - Creating index, part 3/6\n",
      "2016-04-13 18:42:08,221 - DEBUG - Creating index, part 4/6\n",
      "2016-04-13 18:42:12,644 - DEBUG - Creating index, part 5/6\n",
      "2016-04-13 18:42:17,651 - DEBUG - Creating index, part 6/6\n",
      "2016-04-13 18:42:37,275 - DEBUG - Start calc group activity\n",
      "2016-04-13 18:42:44,563 - DEBUG - Processed 100000 domains\n",
      "2016-04-13 18:42:50,598 - DEBUG - Processed 200000 domains\n",
      "2016-04-13 18:42:57,393 - DEBUG - Processed 300000 domains\n",
      "2016-04-13 18:43:03,066 - DEBUG - Processed 400000 domains\n",
      "2016-04-13 18:43:08,365 - DEBUG - Processed 500000 domains\n",
      "2016-04-13 18:43:12,871 - DEBUG - Processed 600000 domains\n",
      "2016-04-13 18:43:17,468 - DEBUG - Processed 700000 domains\n",
      "2016-04-13 18:43:21,986 - DEBUG - Processed 800000 domains\n",
      "2016-04-13 18:43:26,456 - DEBUG - Processed 900000 domains\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\"\"\"\n",
    "fnames = [\n",
    "    \"/home/ivan/dns-03-aprl/querylog.bin.33-1459677601\",\n",
    "    \"/home/ivan/dns-03-aprl/querylog.bin.33-1459681201\",\n",
    "    \"/home/ivan/dns-03-aprl/querylog.bin.33-1459684801\",\n",
    "]\n",
    "\n",
    "apriori_fnames = [\n",
    "     \"/home/ivan/3_aprl_blacklist\",\n",
    "     \"/home/ivan/dns-whitelist/top-1m\",\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "fnames = [\n",
    "    \"/home/ivan/dns-13-aprl/querylog.bin.33-1460530801\",\n",
    "    \"/home/ivan/dns-13-aprl/querylog.bin.33-1460534401\",\n",
    "    \"/home/ivan/dns-13-aprl/querylog.bin.33-1460538001\",\n",
    "    \"/home/ivan/dns-13-aprl/querylog.bin.33-1460541601\",\n",
    "    \"/home/ivan/dns-13-aprl/querylog.bin.33-1460545201\",\n",
    "    \"/home/ivan/dns-13-aprl/querylog.bin.33-1460548801\",\n",
    "]\n",
    "\n",
    "apriori_fnames = [\n",
    "     \"/home/ivan/13_aprl_blacklist\",\n",
    "     \"/home/ivan/dns-whitelist/top-1m\",\n",
    "]\n",
    "\n",
    "preprocessing = Pipeline([\n",
    "        ('raw_pairs', BLReader(fields=[\"client_ip\", \"dname\"])),\n",
    "        ('clean_pairs', PairExtractor()),\n",
    "        ('indexes', IndexCreator())\n",
    "])\n",
    "group_activity = Pipeline([\n",
    "        (\"selector\", ItemSelector(key=\"d2ip\")),\n",
    "        (\"grp_act\", GroupActivity())\n",
    "])\n",
    "\n",
    "indexes = preprocessing.transform(fnames)\n",
    "ip2d_full, d2ip_full = IndexMerger().transform(indexes)\n",
    "group_act = group_activity.transform(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем и вычищаем обучающую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-04-13 18:43:27,460 - DEBUG - Read file /home/ivan/13_aprl_blacklist\n",
      "2016-04-13 18:43:32,034 - DEBUG - Read file /home/ivan/dns-whitelist/top-1m\n",
      "2016-04-13 18:43:37,407 - DEBUG - Positive size 886849, Negative size 959379, Intersection 875\n",
      "2016-04-13 18:43:37,824 - DEBUG - Positive after 3923, Negative after 83564\n"
     ]
    }
   ],
   "source": [
    "read_aprior_info = Pipeline([\n",
    "        (\"reader\", PosNegDomainReader()),\n",
    "        (\"form_sets\", FormXy(group_act.keys()))\n",
    "])\n",
    "X, y = read_aprior_info.transform(apriori_fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидируем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-04-13 18:43:38,255 - DEBUG - Initialize scores\n",
      "2016-04-13 18:43:38,566 - DEBUG - Iteration 1\n",
      "2016-04-13 18:43:58,235 - DEBUG - Iteration 2\n",
      "2016-04-13 18:44:18,432 - DEBUG - Iteration 3\n",
      "2016-04-13 18:44:38,644 - DEBUG - Iteration 4\n",
      "2016-04-13 18:44:58,798 - DEBUG - Iteration 5\n",
      "2016-04-13 18:45:18,965 - DEBUG - Iteration 6\n",
      "2016-04-13 18:45:39,093 - DEBUG - Iteration 7\n",
      "2016-04-13 18:45:59,261 - DEBUG - Iteration 8\n",
      "2016-04-13 18:46:19,402 - DEBUG - Iteration 9\n",
      "2016-04-13 18:46:39,589 - DEBUG - Iteration 10\n",
      "2016-04-13 18:46:59,742 - DEBUG - Iteration 11\n",
      "2016-04-13 18:47:19,892 - DEBUG - Iteration 12\n",
      "2016-04-13 18:47:40,097 - DEBUG - Iteration 13\n",
      "2016-04-13 18:48:00,284 - DEBUG - Iteration 14\n",
      "2016-04-13 18:48:20,471 - DEBUG - Iteration 15\n",
      "2016-04-13 18:48:40,676 - DEBUG - Iteration 16\n",
      "2016-04-13 18:49:00,795 - DEBUG - Iteration 17\n",
      "2016-04-13 18:49:20,944 - DEBUG - Iteration 18\n",
      "2016-04-13 18:49:41,086 - DEBUG - Iteration 19\n",
      "2016-04-13 18:50:01,198 - DEBUG - Iteration 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preparation', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('ranking', <__main__.SecureRank object at 0x7faa295cd150>), ('group_activities', IndentityOp(info={'samasyangin.com': {'(1, 3)_length': 0.0, '(0, 1)_jcd': 0.0, '(0, 5)_jcd': 0.0, '(2, 4)_length': 0.0, '(4, 5)_jcd': 0.0, '(3, 4)_...thm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=42))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_score, classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "union = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        ('ranking', SecureRank(ip2d_full, d2ip_full, max_iter=20)),\n",
    "        ('group_activities', IndentityOp(group_act))\n",
    "    ])\n",
    "\n",
    "clf = Pipeline([\n",
    "        ('preparation', union),\n",
    "        ('final_score', AdaBoostClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_roc = clf.predict_proba(X_test)[:,1]\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-04-13 19:08:49,167 - DEBUG - Initialize scores\n",
      "2016-04-13 19:08:49,771 - DEBUG - Iteration 1\n",
      "2016-04-13 19:09:09,509 - DEBUG - Iteration 2\n",
      "2016-04-13 19:09:29,801 - DEBUG - Iteration 3\n",
      "2016-04-13 19:09:50,069 - DEBUG - Iteration 4\n",
      "2016-04-13 19:10:10,378 - DEBUG - Iteration 5\n",
      "2016-04-13 19:10:30,644 - DEBUG - Iteration 6\n",
      "2016-04-13 19:10:50,850 - DEBUG - Iteration 7\n",
      "2016-04-13 19:11:11,192 - DEBUG - Iteration 8\n",
      "2016-04-13 19:11:31,430 - DEBUG - Iteration 9\n",
      "2016-04-13 19:11:51,708 - DEBUG - Iteration 10\n",
      "2016-04-13 19:12:12,110 - DEBUG - Iteration 11\n",
      "2016-04-13 19:12:32,303 - DEBUG - Iteration 12\n",
      "2016-04-13 19:12:52,517 - DEBUG - Iteration 13\n",
      "2016-04-13 19:13:12,835 - DEBUG - Iteration 14\n",
      "2016-04-13 19:13:33,041 - DEBUG - Iteration 15\n",
      "2016-04-13 19:13:53,211 - DEBUG - Iteration 16\n",
      "2016-04-13 19:14:13,614 - DEBUG - Iteration 17\n",
      "2016-04-13 19:14:33,889 - DEBUG - Iteration 18\n",
      "2016-04-13 19:14:54,150 - DEBUG - Iteration 19\n",
      "2016-04-13 19:15:14,470 - DEBUG - Iteration 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preparation', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('ranking', <__main__.SecureRank object at 0x7faa295cd150>), ('group_activities', IndentityOp(info={'samasyangin.com': {'(1, 3)_length': 0.0, '(0, 1)_jcd': 0.0, '(0, 5)_jcd': 0.0, '(2, 4)_length': 0.0, '(4, 5)_jcd': 0.0, '(3, 4)_...thm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=42))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_graph = d2ip_full.keys()\n",
    "y_graph_prob = clf.predict_proba(X_graph)[:, np.where(clf.classes_ == 1)[0][0]]\n",
    "y_graph_labels = clf.predict(X_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = sorted(zip(X_graph, y_graph_prob, y_graph_labels), key=lambda x: x[1], reverse=True)\n",
    "with open('/home/ivan/13-aprl-lastresult.txt', 'w') as outfile:\n",
    "    for domain, prob, lab in result:\n",
    "        outfile.write(\"{}\\t{}\\t{}\\n\".format(domain, prob, lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_new = clf.predict_proba(X_test)\n",
    "plt.hist(y_new[:,1][np.where(y_test > 0)], bins=30, color='r', alpha=0.5, normed=True)\n",
    "plt.hist(y_new[:,1][np.where(y_test < 0)], bins=30, color='b', alpha=0.5, normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC 0.971075609507\n",
      "PRECISION 0.992869875223\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      1.00      1.00     25065\n",
      "          1       0.99      0.94      0.97      1182\n",
      "\n",
      "avg / total       1.00      1.00      1.00     26247\n",
      "\n",
      "TP:1114 | FP: 68| TN: 25057| FN: 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, classification_report\n",
    "print(\"ROC-AUC {}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"PRECISION {}\".format(precision_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "TP, TN, FP, FN = perf_measure(y_pred, y_test)\n",
    "print(\"TP:{} | FP: {}| TN: {}| FN: {}\".format(TP, FP, TN, FN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
